<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <title>Mediapipe Landmarker</title>
    <style>
        /* Hide the Canvas element initially */
        #outputCanvas {
            display: none;
        }
    </style>
</head>

<body>
    <canvas id="outputCanvas"></canvas>
    <!-- Include TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script type="module">
        // Import Mediapipe Tasks
        import { FaceLandmarker, PoseLandmarker, HandLandmarker, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

        let faceLandmarker = null;
        let poseLandmarker = null;
        let handLandmarker = null;
        let models = {};

        // Create Mediapipe Landmarker instances
        async function createLandmarkers() {
            console.log('Creating Mediapipe Landmarkers...');
            try {
                const vision = await FilesetResolver.forVisionTasks(
                    'https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm'
                );

                // Create FaceLandmarker
                faceLandmarker = await FaceLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/face_landmarker/face_landmarker/float16/1/face_landmarker.task',
                        delegate: 'GPU'
                    },
                    runningMode: 'IMAGE',
                    numFaces: 1,
                });

                // Create PoseLandmarker
                poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_heavy/float16/1/pose_landmarker_heavy.task',
                        delegate: 'GPU'
                    },
                    runningMode: 'IMAGE',
                });

                // Create HandLandmarker
                handLandmarker = await HandLandmarker.createFromOptions(vision, {
                    baseOptions: {
                        modelAssetPath: 'https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task',
                        delegate: 'GPU'
                    },
                    runningMode: 'IMAGE',
                    numHands: 1,
                });

                console.log('Mediapipe Landmarkers created');
            } catch (error) {
                console.error('Error creating Mediapipe Landmarkers:', error);
            }
        }

        // Load custom models
        async function loadModels() {
            console.log('Loading custom models...');
            // You can load models as needed based on the modelName
            // For this example, we'll load models dynamically in runModel()
        }

        // Preprocess landmarks
        function preprocessLandmarks(landmarks) {
            const input = [];
            for (let i = 0; i < landmarks.length; i++) {
                input.push(landmarks[i].x);
                input.push(landmarks[i].y);
                input.push(landmarks[i].z || 0);
            }

            const inputTensor = tf.tensor(input, [1, input.length]);
            return inputTensor;
        }

        // Run model and get predictions
        async function runModel(inputTensor, modelName) {
            let model = models[modelName];
            if (!model) {
                // Load the model dynamically
                try {
                    const indexedDBUrl = `indexeddb://${modelName}`;
                    try {
                        model = await tf.loadGraphModel(indexedDBUrl);
                        console.log(`Custom model ${modelName} loaded successfully from IndexedDB`);
                    } catch (error) {
                        console.warn(`Could not load model ${modelName} from IndexedDB, loading from network...`, error);
                        try {
                            // Load from the network (replace with your actual URL)
                            const networkModelUrl = `https://your.model.server/path/to/${modelName}/model.json`;
                            model = await tf.loadGraphModel(networkModelUrl);
                            console.log(`Custom model ${modelName} loaded successfully from network`);
                            // Save the model to IndexedDB for offline use
                            await model.save(indexedDBUrl);
                            console.log(`Custom model ${modelName} saved to IndexedDB`);
                        } catch (networkError) {
                            console.error(`Error loading custom model ${modelName} from network:`, networkError);
                            return null;
                        }
                    }
                    models[modelName] = model;
                } catch (error) {
                    console.error(`Error loading model ${modelName}:`, error);
                    return null;
                }
            }

            try {
                const inputName = model.inputs[0].name;
                const prediction = model.execute({ [inputName]: inputTensor });

                let predictionData;
                if (Array.isArray(prediction)) {
                    predictionData = [];
                    for (let tensor of prediction) {
                        const data = tensor.dataSync();
                        predictionData = predictionData.concat(Array.from(data));
                        tensor.dispose();
                    }
                } else {
                    predictionData = prediction.dataSync();
                    prediction.dispose();
                }

                return predictionData;
            } catch (error) {
                console.error(`Error during model ${modelName} execution:`, error);
                if (error.stack) {
                    console.error('Stack trace:', error.stack);
                }
                return null;
            }
        }

        // Main processing function
        async function processImage(imageData, mediapipeTasks, modelName) {
            if (!faceLandmarker || !poseLandmarker || !handLandmarker) {
                console.error('Landmarkers not initialized');
                return null;
            }

            try {
                let combinedLandmarks = [];

                for (let task of mediapipeTasks) {
                    let landmarks = null;

                    if (task === "face") {
                        const results = await faceLandmarker.detect(imageData);
                        if (results.faceLandmarks && results.faceLandmarks.length > 0) {
                            landmarks = results.faceLandmarks[0];
                            // Lock to 468 landmarks for face
                            landmarks = landmarks.slice(0, 468);
                        } else {
                            console.log('No face landmarks detected.');
                            return null;
                        }
                    } else if (task === "pose") {
                        const results = await poseLandmarker.detect(imageData);
                        if (results.landmarks && results.landmarks.length > 0) {
                            landmarks = results.landmarks[0];
                        } else {
                            console.log('No pose landmarks detected.');
                            return null;
                        }
                    } else if (task === "hand") {
                        const results = await handLandmarker.detect(imageData);
                        if (results.handLandmarks && results.handLandmarks.length > 0) {
                            landmarks = results.handLandmarks[0];
                        } else {
                            console.log('No hand landmarks detected.');
                            return null;
                        }
                    } else {
                        console.error('Invalid mediapipeTask:', task);
                        return null;
                    }

                    combinedLandmarks = combinedLandmarks.concat(landmarks);
                }

                // Preprocess combined landmarks
                const inputTensor = preprocessLandmarks(combinedLandmarks);

                // Run the model
                const predictions = await runModel(inputTensor, modelName);

                return predictions;

            } catch (error) {
                console.error('Error during detection:', error);
                return null;
            }
        }

        // Function exposed to Swift to process image data
        function processImageData(base64Image, mediapipeTasksString, modelName) {
            const mediapipeTasks = mediapipeTasksString.split(',').map(task => task.trim());

            try {
                const image = new Image();
                image.src = 'data:image/jpeg;base64,' + base64Image;

                image.onload = async () => {
                    const canvas = document.createElement('canvas');
                    canvas.width = image.width;
                    canvas.height = image.height;
                    const ctx = canvas.getContext('2d');

                    // Flip the image vertically (Y-axis flip)
                    ctx.scale(1, -1);
                    ctx.drawImage(image, 0, -canvas.height, canvas.width, canvas.height);

                    const imageData = ctx.getImageData(0, 0, canvas.width, canvas.height);

                    try {
                        const predictions = await processImage(imageData, mediapipeTasks, modelName);

                        if (predictions) {
                            window.webkit.messageHandlers.callbackHandler.postMessage(predictions.join(','));
                        } else {
                            window.webkit.messageHandlers.callbackHandler.postMessage('null');
                        }
                    } catch (error) {
                        console.error('Error during image processing:', error);
                        window.webkit.messageHandlers.callbackHandler.postMessage('null');
                    }
                };

                image.onerror = (error) => {
                    console.error('Image load error:', error);
                    window.webkit.messageHandlers.callbackHandler.postMessage('null');
                };
            } catch (error) {
                console.error('Error in processImageData:', error);
                window.webkit.messageHandlers.callbackHandler.postMessage('null');
            }
        }

        // Initialize the application
        async function initialize() {
            console.log('Initializing...');
            await createLandmarkers();
            // We can load models when needed in runModel()
            console.log('Initialization complete');
        }

        // Initialize
        initialize();

        // Expose the processImageData function to the window object
        window.processImageData = processImageData;
    </script>
</body>

</html>
